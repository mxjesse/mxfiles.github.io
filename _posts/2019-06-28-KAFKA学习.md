# 

### 前言

#### 官网简介
[Kfka官网简介](http://kafka.apache.org/intro)，原文如下
>Apache Kafka® is a distributed streaming platform.
>>A streaming platform has three key capabilities:
>>
  * Publish and subscribe to streams of records, similar to a message queue or enterprise messaging system.
  * Store streams of records in a fault-tolerant durable way.
  * Process streams of records as they occur.

>>Kafka is generally used for two broad classes of applications:
>>
  * Building real-time streaming data pipelines that reliably get data between systems or applications
  * Building real-time streaming applications that transform or react to the streams of data

>To understand how Kafka does these things, let's dive in and explore Kafka's capabilities from the bottom up.

>First a few concepts:
>
  * Kafka is run as a cluster on one or more servers that can span multiple datacenters.
  * The Kafka cluster stores streams of records in categories called topics.
Each record consists of a key, a value, and a timestamp.

翻译一下：   
Apache kafka是一个分布式流处理平台。
一个流处理平台有三个关键的能力：

  * 发布和订阅流记录，类似于消息队列或者企业级消息系统。
  * 以容错耐用方式存储流记录
  * 当流记录产生时处理流记录

kafka通常被使用在两个应用之间：

  * 建立实时流数据管道，在系统或应用之间可靠地获得数据
  * 建立对数据流进行转换或响应的的实时流应用程序

去理解kafka怎么做这些事情的，我们从下到上深入理解kafka的能力。

首先几个概念：
  
  * kafka是作为一个集群运行在一个或多个可以跨多个数据中心的服务上
  * kafka集群储存的分类的流记录称为主题（topic）。每一个记录由一个key，一个value和一个时间戳组成。

#### 几个概念

##### topic
一个topic可以当作一类消息，每个topic都会被分为多个partition（分区），每个partition在文件中都以append log文件存储。任何被发布到partition的消息都会被直接追加到log文件的尾部，每条消息在log中的位置被称为offset（偏移量），offset是一个long类型的数字，它是唯一标记一条消息的。

kakfa即使消息被消费，消息也不会立即删除，log文件会根据broker中的配置，保留一定时间后删除（比如设置X天后删除，无论消息是否被消费，X天后此消息会被清除），kafka通过这种手段，来释放磁盘空间，以及减少频繁改动文件内容对磁盘IO的开支。

consumer（消费者），它需要保存消费消息的offset，对于offset的保存和使用，由consumer来控制，当consumer正常地消费消息时，offset会线性向前驱动，即消息顺序被消费。不过，consumer也可以使用任意顺序消费消息，只需要将offset设置为对应的值。

kafka集群几乎不用维护任何consumer和producer状态信息，这些信息由zookeeper保存，因此kafka的producer和consumer客户端实现都比较轻量。

partition设计原因是kafka是基于文件存储，通过分区可以将日志文件分散在cluster中多个server上，来避免产生文件过大，达到机器存储上限，每个partition会被当前server保存，将一个topic切割成多个partitions，来提高 消费/保存 消息的效率。

##### partition
一个Topic的多个partitions，被分布在kafka集群中的多个server上，每个server负责读写自己partition中消息，此外kafka还可以配置partition需要备份（replica）的备份个数，每个partition将被备份到多台机器上，以提高可用性。

基于replicated方案,那么就意味着需要对多个备份进行调度;每个partition都有一个server为leader，leader负责所有的读写操作，如果leader失效，那么将会有其他follower来接管(成为新的leader)；follower只是单调的和leader跟进，同步消息即可。由此可见作为leader的server承载了全部的请求压力，因此从集群的整体考虑，有多少个partitions就意味着有多少个leader，kafka会将leader均衡的分散在每个实例上，来确保整体的性能稳定。

##### Producers
Producer将消息发布到指定的Topic中，同时Producer也能决定将此消息归属于哪个partition；比如基于round-robin（轮询）方式或者通过其他的一些算法等.
 
##### Consumers
本质上kafka只支持Topic，每个consumer属于一个consumer group。反过来说，每个group中可以有多个consumer。发送到Topic的消息,只会被订阅此Topic的每个group中的一个consumer消费。

---

#### 配置文件
kafka的配置文件在kafka目录下 [kafka目录]/config/server.properties，要修改kafka的配置修改此文件即可，文件内容如下：

```
############################# Server Basics #############################

#此节点的id，集群中各节点的此值必须是一个唯一的integer数
broker.id=0

############################# Socket Server Settings #############################

#套接字监听的地址，如果未设置，它将使用java.net.InetAddress.getCanonicalHostName()的返回值
#listeners=PLAINTEXT://:9092
#节点的主机名和端口会通知给生产者和消费者，如果未设置，它将使用listeners配置的值，否则就使用java.net.InetAddress.getCanonicalHostName()的返回值
#advertised.listeners=PLAINTEXT://your.host.name:9092

#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
#服务器用来接收请求和发送返回值的线程数
num.network.threads=3
#服务器用来处理请求的线程数，可能包括磁盘IO
num.io.threads=8
#套接字服务使用的发送缓冲区大小
socket.send.buffer.bytes=102400
#套接字服务使用的接收缓冲区大小
socket.receive.buffer.bytes=102400
#套接字服务能接收的请求的最大数据量
socket.request.max.bytes=104857600

############################# Log Basics #############################
#以逗号分隔的目录列表，用来储存日志文件
log.dirs=/tmp/kafka-logs
#每个主题的默认日志分区数量，更多的分区数量允许更多的并行消费，但是它也会导致节点产生更多的文件
num.partitions=1
#每个数据目录中的线程数，用于启动时的日志恢复和关闭时的刷新
num.recovery.threads.per.data.dir=1

############################# Internal Topic Settings  #############################
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1

############################# Log Flush Policy #############################

#在强制刷新数据到硬盘之前允许的消息数量
#log.flush.interval.messages=10000
#强制刷新前，消息可在日志中停留的最长时间
#log.flush.interval.ms=1000

############################# Log Retention Policy #############################
#日志到期可以被删除的最小时间
log.retention.hours=168
#一个基于大小的日志保留策略。段将被从日志中删除只要剩下的部分段不低于log.retention.bytes。
#log.retention.bytes=1073741824
#日志段文件的最大大小，当达到这个值的时候一个新的日志段会生成
log.segment.bytes=1073741824
#检查日志段的时间间隔，根据保留策略看是否能删除它
log.retention.check.interval.ms=300000

############################# Zookeeper #############################
#zookeeper连接字符串，是以逗号分隔的（主机名：端口号）对，每一个都对应一个zk服务器，例如："127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
zookeeper.connect=localhost:2181
#连接到zookeeper的超时时间
zookeeper.connection.timeout.ms=6000


############################# Group Coordinator Settings #############################

# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.
# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.
# The default value for this is 3 seconds.
# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.
# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.
group.initial.rebalance.delay.ms=0

```